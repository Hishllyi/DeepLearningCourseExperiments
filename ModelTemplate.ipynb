{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# 设置中文支持\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom datasets\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_folder, transform=None):\n",
    "        self.data_folder = data_folder\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 将传入目录下的文件名转换为列表\n",
    "        self.classes = os.listdir(data_folder)\n",
    "        # 建立类别索引\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "        # 数据成员变量，其元素均为元组数据类型，每一个元组构成为（图像路径名，类别索引）\n",
    "        self.data = self.load_data()\n",
    "        # 对数据进行打乱\n",
    "        random.shuffle(self.data)\n",
    "\n",
    "    def load_data(self):\n",
    "        data = []\n",
    "        for cls_name in self.classes:\n",
    "            # 按类别获取图像文件夹的路径\n",
    "            cls_folder = os.path.join(self.data_folder, cls_name)\n",
    "            # 过滤文件后缀并存储同类图像的路径为列表\n",
    "            images = [os.path.join(cls_folder, img_name) for img_name in os.listdir(cls_folder) if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif'))]\n",
    "            # 获取该类图像的类别索引\n",
    "            class_idx = self.class_to_idx[cls_name]\n",
    "            # 将可迭代的列表添加到data中\n",
    "            data.extend([(img_path, class_idx) for img_path in images])\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_idx = self.data[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, class_idx\n",
    "\n",
    "# Data folder path\n",
    "data_folder = r\"Data folder path\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = CustomDataset(data_folder, transform=transform)\n",
    "# 划分数据集\n",
    "total_samples = len(dataset)\n",
    "train_samples = int(0.7 * total_samples)\n",
    "test_samples = total_samples - train_samples\n",
    "\n",
    "# 划分训练集和测试集\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_samples, test_samples])\n",
    "\n",
    "# 定义batch_size\n",
    "batch_size = 32\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"训练集大小：\", len(train_dataset))\n",
    "print(\"测试集大小：\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证数据集分类正确性\n",
    "for i in range(5):\n",
    "    plt.figure()\n",
    "    print(train_dataset[i+34][1])\n",
    "    plt.imshow(transforms.ToPILImage()(train_dataset[i+34][0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 函数准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 绘图函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练损失和测试损失的函数\n",
    "def plot_loss(train_loss, test_loss, title):\n",
    "    plt.figure(figsize=(8, 4), dpi=100)\n",
    "    x = np.arange(len(train_loss))\n",
    "    plt.plot(x, train_loss, label=\"train loss\", color=\"red\", marker='v', markersize=5, linewidth=2)\n",
    "    plt.plot(x, test_loss, label=\"test loss\", color=\"blue\", marker='o', markersize=5, linewidth=2)\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 绘制训练精度和测试精度的函数\n",
    "def plot_acc(train_acc, test_acc, title):\n",
    "    plt.figure(figsize=(8, 4), dpi=100)\n",
    "    x = np.arange(len(train_acc))\n",
    "    plt.plot(x, train_acc, label=\"train acc\", color=\"red\", marker='v', markersize=5, linewidth=2)\n",
    "    plt.plot(x, test_acc, label=\"test acc\", color=\"blue\", marker='o', markersize=5, linewidth=2)\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 绘制损失值对比函数\n",
    "def loss_comparison(losses, labels, title):\n",
    "    markers = ['o', 'v', 'p', '*', 'h', 'H', '+', 'x', 'D', 'd']\n",
    "    plt.figure(figsize=(8, 4), dpi=100)\n",
    "    x = np.arange(len(losses[0]))\n",
    "    for idx, loss in enumerate(losses):\n",
    "        plt.plot(x, loss, label=labels[idx], marker=markers[idx], markersize=5, linewidth=2)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 定义训练时间对比图\n",
    "def train_time_comparison(times, labels, title):\n",
    "    plt.figure(dpi=100)\n",
    "    bars = plt.bar(labels, times, color=['blue', 'green', 'red'])\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Training Time (seconds)')\n",
    "\n",
    "    # 在每个柱子上方显示时间数据\n",
    "    for bar, time in zip(bars, times):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 5, str(time), ha='center', color='black', fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "def train_model(model, data_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    train_batch_num = len(data_loader)\n",
    "    total_loss = 0\n",
    "    correct = 0     # 记录分类正确数\n",
    "    sample_num = 0  # 记录样本总数\n",
    "\n",
    "    # 遍历每个batch进行训练\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        # 将图片放入指定的device中\n",
    "        data, target = data.to(device).float(), target.to(device).long()\n",
    "\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        # 前向传播\n",
    "        output = model(data)\n",
    "        # 计算损失\n",
    "        loss = criterion(output, target)\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 更新梯度\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 累加loss\n",
    "        total_loss += loss.item()\n",
    "        prediction = torch.argmax(output, 1)\n",
    "        # 统计正确数\n",
    "        correct += (prediction == target).sum().item()\n",
    "        # 累加当前样本数量\n",
    "        sample_num += len(prediction)\n",
    "\n",
    "    loss = total_loss / train_batch_num\n",
    "    acc = correct / sample_num\n",
    "    return loss, acc\n",
    "\n",
    "# 测试函数\n",
    "def test_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_batch_num = len(data_loader)\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    sample_num = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            data, target = data.to(device).float(), target.to(device).long()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            prediction = torch.argmax(output, 1)\n",
    "            correct += (prediction == target).sum().item()\n",
    "            sample_num += len(prediction)\n",
    "\n",
    "    loss = total_loss / test_batch_num\n",
    "    acc = correct / sample_num\n",
    "    return loss, acc\n",
    "\n",
    "# 模型训练过程函数\n",
    "def train(model, train_loader, test_loader, criterion, optimizer, epochs, device):\n",
    "    # 训练模型并验证\n",
    "    train_losses = []\n",
    "    train_acc_list = []\n",
    "    test_losses = []\n",
    "    test_acc_list = []\n",
    "    start = time.time()\n",
    "\n",
    "    # 进行训练\n",
    "    for epoch in range(epochs):\n",
    "        # 在训练集上训练\n",
    "        train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, device=device)\n",
    "\n",
    "        # 在测试集上训练\n",
    "        test_loss, test_acc = test_model(model, test_loader, criterion, device=device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "        print(f'Epoch: {epoch + 1}/{epochs},\\t train_loss: {train_loss:.4f},\\t train_acc: {train_acc:.4f},\\t test_loss: {test_loss:.4f},\\t test_acc: {test_acc:.4f}')\n",
    "\n",
    "    end = time.time()\n",
    "    print(f'\\n训练结毕，耗时：{end - start}s')\n",
    "    return train_losses, train_acc_list, test_losses, test_acc_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型定性分析函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型定性分析的函数\n",
    "def qualitative_Analysis(model, datasets, mdoelPath):\n",
    "    checkpoint = torch.load(mdoelPath)  # 替换为你的模型检查点文件路径\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "\n",
    "    # 使用模型进行预测\n",
    "    with torch.no_grad():\n",
    "        output = []\n",
    "        output1 = model(datasets[0][0].unsqueeze(0).to(device)).squeeze()\n",
    "        output2 = model(datasets[1][0].unsqueeze(0).to(device)).squeeze()\n",
    "        output.append(output1)\n",
    "        output.append(output2)\n",
    "\n",
    "    # 抽样显示训练集中图片\n",
    "    fig, axes = plt.subplots(2, 3)\n",
    "    fig.subplots_adjust(wspace=0.1, hspace=0)\n",
    "    fig.suptitle(\"带雾图——模型输出图——去雾图\", fontsize=10)\n",
    "    for i in range(2):\n",
    "        axes[i][0].imshow(transforms.ToPILImage()(datasets[i][0]))\n",
    "        axes[i][0].axis('off')\n",
    "        axes[i][1].imshow(transforms.ToPILImage()(output[i]))\n",
    "        axes[i][1].axis('off')\n",
    "        axes[i][2].imshow(transforms.ToPILImage()(datasets[i][1]))\n",
    "        axes[i][2].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型搭建\n",
    "class ModuleName(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModuleName, self).__init__()\n",
    "        # \n",
    "    \n",
    "    def forward(self, X):\n",
    "        output = \n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model output\n",
    "model = ModuleName().to(device)\n",
    "output = model(train_dataset[1][0].unsqueeze_(0).to(device)).squeeze()\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters and model\n",
    "epochs = 20\n",
    "lr = 0.001\n",
    "\n",
    "model = ModuleName().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# train model\n",
    "train_losses, train_acc_list, test_losses, test_acc_list = train(model, train_loader, test_loader, criterion, optimizer, epochs, device)\n",
    "\n",
    "# 保存模型的状态字典和其他信息到文件\n",
    "model_state = model.state_dict()\n",
    "other_info = {'epoch': epochs, 'train_losses': train_losses, 'train_acc_list':train_acc_list, 'test_losses': test_losses, 'test_acc_list':test_acc_list}\n",
    "torch.save({'model_state': model_state, 'other_info': other_info}, 'modelPath.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型损失变化图\n",
    "plot_loss(train_losses, test_losses, title=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练精度变化图\n",
    "plot_acc(train_acc_list, test_acc_list, title='title')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
